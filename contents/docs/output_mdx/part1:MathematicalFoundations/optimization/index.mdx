# Optimization \{#chap:optimization\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:calculus\]](#chap:calculus)\{reference-type="ref+label"
reference="chap:calculus"\}\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------

Both machine learning and physics require methods to find points of
functions that satisfy certain maximal or minimal criteria: for example
the \"highest\" point on a 1D function. Optimization is the field of
mathematics that provides procedures to find such special points. In the
case that the functions in question take values on function spaces, then
optimization turns into the problem of finding a function with a desired
property, a technique of powerful physical importance.

## Optimizing Simple Functions

As a simple example, let us suppose that we have a function
$f: \mathbb\{R\} \to \mathbb\{R\}$. How can we find the extrema of $f$? The
first place to start looking is at the zeros of the derivative $f'$. For
example, suppose that $f(x) = x^2$, then $f'(x) = 2x$ which has a zero
at $x=0$. This is the minima of $f$. This rule isn't perfect though.
Suppose $g(x) = x^3$. Then $g'(x) = 3x^2$ which also has a zero at
$x=0$, but this isn't a minima of $g$.

## Lagrange Multipliers

Lagrange multipliers are a technique for finding minima that satisfy
constraints. For example, suppose that
$f, g: \mathbb\{R\}^3 \to \mathbb\{R\}$ are functions of three variables.
Then we would like to solve the problem. $$\begin\{aligned\}
    \min &\quad f(x, y, z)\\
    \textrm\{s. t.\} &\quad g(x, y, z) = k
\end\{aligned\}$$

The technique for doing this is to find a spot such that the gradients
of $f$ and $g$ point in the same direction and where the constraint is
satisified. That is, we construct the following set of equations.

$$\begin\{aligned\}
    \nabla f(x, y, z) &= \nabla g(x, y, z) \\
    g(x, y, z) &= k
\end\{aligned\}$$

Then check all solutions of this set of equations for those which are
minima/maxima of the original equation. As a singularity check, also
verify that the gradient of $g$ is not zero at that point either.

## Adjoint Method

Let $u \in \mathcal\{U\}$ be a state variable. Let $v \in \mathcal\{V\}$ be
an optimization variable. Let $$\begin\{aligned\}
J: \mathcal\{U\} \times \mathcal\{V\} \to \mathbb\{R\}
\end\{aligned\}$$ be a function and considered the objective function
$$\begin\{aligned\}
    j(v) &= J(u(v), v)
\end\{aligned\}$$ We can then formulate the optimization problem
$$\begin\{aligned\}
    & \textrm\{minimize\}\ j(v) = J(u_v, v) \\
    & \textrm\{subject to\}\ D_v(u) = 0
\end\{aligned\}$$ We wish to compute the total derivative $d_\theta j$
subject to the constraint $D_v(u) = 0$. Create the Lagrangian
$$\begin\{aligned\}
    \mathcal\{L\}(u, v, \lambda) &= J(u, v) + \lambda D_v(u) \rangle 
\end\{aligned\}$$ The method of Lagrange multipliers means solution has to
be a stationary point of Lagrangian. The adjoint then comes out
$$\begin\{aligned\}
d_\theta f(x) &= \lambda^T g_\theta
\end\{aligned\}$$

## Convex Optimization

Convex problems can be exactly solved by gradient descent and related
optimization methods.

## Calculus of Variations

Differential calculus is concerned with the task of finding the extreme
values of functions of one or more variables. This can be done by
finding points where the derivative of the function is 0. However, in
some cases, we will be interested in finding an extreme point in a set
of functions.

The *brachistochrone problem* is a famous example of such a task. This
challenge, first posed in 1692, asks for the curve between two points
$A$, $B$ through which a particle acted upon only by gravity can move
from $A$ to $B$. In order for us to be able to solve this problem, we
will have to introduce some machinery.

Let $\mathcal\{F\}$ be a space of functions. A function
$J: \mathcal\{F\} \to \mathbb\{R\}$ is said to be a *functional*. We denote
the evaluation of $J$ on $f \in \mathcal\{F\}$ as $J[f]$. We say that $J$
has an local maximum at $f$ if for all $y$ which are in a neighborhood
of $f$, $J[y] \geq J[f]$. Alternatively, if $J[y] \leq J[f]$ for all
such $y$, we say $J$ has a local minimum

If you haven't worked with functionals before, this definition might be
a little opaque. Let's look at an example. Let $x_1, x_2 \in \mathbb\{R\}$
be constants. Let $y: \mathbb\{R\} \to \mathbb\{R\}$ be a twice
differentiable function. Let $L: \mathbb\{R\}^3 \to \mathbb\{R\}$ be a twice
differentiable function. Then we define
$$J[f] = \int_\{x_1\}^\{x_2\} L(x, f(x), f'(x)) dx$$

Here $f' = \frac\{df\}\{dx\}$. How can we find the minima of $J$? We
typically do so by solving the *Euler-Lagrange equations*.
$$\frac\{\partial L\}\{\partial f\} = \frac\{d\}\{dx\} \frac\{\partial L\}\{\partial f'\}$$

In the exercises, we'll provide some examples of using the
Euler-Lagrange equations on practice problems

### Exercises

1.  Let $f(x) = 4x^2 - 3y$. Find the extrema of $f$ on the circle
    $x^2 + y^2 = 4$.

2.  Let $(x_1, y_1), (x_2, y_2) \in \mathbb\{R\}^2$ be tuples of points.
    We would like to to find the shortest path that connects
    $(x_1, y_1)$ and $(x_2, y_2)$. We define a functional that computes
    the arc-length of a curve.
    $$A[f] = \int_\{x_1\}^\{x_2\} \sqrt\{1 + (f'(x))^2\} dx$$

    1.  Let $g$ be the straight line that connects $(x_1, y_1)$ and
        $(x_2, y_2)$. Write down the equation of $g$.

    2.  Compute $A[g]$. Try a few other paths between these points and
        convince yourself that the arclength is smallest for $g$.

    3.  Show that $\frac\{\partial L\}\{\partial f\} = 0$. Hint: Note that
        $f$ and $f'$ are independent arguments for $L$.

    4.  Show that
        $$\frac\{\partial L\}\{\partial f'\} = \frac\{f'(x)\}\{\sqrt\{1 + (f'(x))^2\}\}$$

    5.  Show that $$\frac\{f'(x)\}\{\sqrt\{1 + (f'(x))^2\}\} = c$$ where
        $c \in \mathbb\{R\}$ is a constant. Hint: plug the results of the
        previous sections into the Euler-Lagrange equations.

    6.  Show that $f'(x)$ must be a constant. Prove that this implies
        $f = g$
