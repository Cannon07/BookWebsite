# Calculus \{#chap:calculus\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:math_basics\]](#chap:math_basics)\{reference-type="ref+label"
reference="chap:math_basics"\}\
**Difficulty Level:** \*\

------------------------------------------------------------------------

This chapter introduces the basics of calculus, starting from continuity
and limits and builds up to Taylor series and antiderivatives.

## Continuity and Limits

In colloquial language, a continuous function is one in which there are
no abrupt shift in values. Adding a little bit more formality, suppose
that we have a function $y = f(x)$ (read as \"f of x\"). Let us suppose
that $\epsilon$ (read as \"epsilon\") is an \"infinitesimally small\"
quantity. Then we say that $f$ is a continuous function if the shift
$f(x + \epsilon) - f(x)$ is also an infinitesimally small quantity. In
the language of \"limits\", we would write this relationship as

$$\lim_\{\epsilon \to 0\} f(x + \epsilon) = f(x)$$

(Read this as \"limit as epsilon approaches zero of f of x plus epsilon
equals f of x\".) Many of you may already be familiar with the notion of
a limit from past mathematics classes. But for those of you who aren't
familiar, let's try to provide a little more intuition. The idea is that
the quantity $\epsilon$ needs to \"get close\" to zero and as it does
so, $f(x + \epsilon)$ should \"get close\" to $f(x)$. The underlying
concept here is that of a *metric*, where a *metric* is a function
$d: A \times A \to [0, \infty)$ that satisfies the following 3 axioms:

1.  $d(x, y) = 0$ if and only if $x = y$

2.  $d(x, y) = d(y, x)$ for all $x, y$

3.  $d(x, y) \leq d(x, z) + d(z, y)$ for all $z$

On the real numbers $\mathbb\{R\}$ (which we haven't yet formally
defined), we define the metric as the absolute value of the difference:
$$d(x, y) = |x - y|$$

A set $A$ with a metric $d$ defined is said to be a \"metric space.\"
With this definition in place, we can define the continuity with the
\"$(\epsilon, \delta)$\" definition. That is, a function $f$ on a metric
space $A$ is continuous if for every $\epsilon > 0$ there exists a
$\delta$ such that if $d(x, y) < \delta$ then
$d(f(x), f(y)) < \epsilon$.

This definition looks a little formal, but the idea is simply that as
$x$ \"gets close\" to $y$, then $f(x)$ must \"get close\" to $f(y)$.

## Differential Calculus

In this section, we'll do a rapid introduction to the calculus that
we'll use throughout this book. Let $f: \mathbb\{R\} \to \mathbb\{R\}$ be a
function. The derivative of $f$, is a function
$\frac\{df\}\{dx\}: \mathbb\{R\} \to \mathbb\{R\}$ which is defined by

$$\begin\{aligned\}
\frac\{df\}\{dx\} = \lim_\{\Delta x \to 0\} \frac\{f(x + \Delta x) - f(x)\}\{\Delta x\}
\end\{aligned\}$$

The quantity $\frac\{df\}\{dx\}$ is read as \"dee f dee x\" and is a measure
of the rate of change of the function $f$ with respect to the input $x$.
We also often use an alternative notation for derivatives

$$\begin\{aligned\}
    f' &= \frac\{df\}\{dx\} 
\end\{aligned\}$$ which we read as \"f prime\". Let's work through a
simple example. We will compute $\frac\{df\}\{dx\}$ for the following
function $$\begin\{aligned\}
    f(x) = 5 x + 6
\end\{aligned\}$$ We use the definition to write $$\begin\{aligned\}
    \frac\{df\}\{dx\} &= \lim_\{\Delta x \to 0\} \frac\{f(x+\Delta x) - f(x)\}\{\Delta x\} \\
    &=  \lim_\{\Delta x \to 0\} \frac\{5(x+\Delta x) + 6 - (5x + 6)\}\{\Delta x\} \\
    &=  \lim_\{\Delta x \to 0\} \frac\{5\Delta x \}\{\Delta x\} \\
    &= 5
\end\{aligned\}$$ That is, $\frac\{df\}\{dx\}$ is the slope of $f$. To compute
derivatives for more complex functions, you can use the formal
definition, but it is often simpler to use some shortcuts that
mathematicians have discovered. The most powerful such shortcut is the
chain rule which states $$\begin\{aligned\}
    \frac\{d f(g(x))\}\{dx\} &= \frac\{df\}\{dx\}(g(x)) \frac\{dg\}\{dx\}
\end\{aligned\}$$ We will use the chain rule systematically later in the
book to compute the derivatives of very complex functions. We will also
note that we will have reason to chain derivatives. Consider the
quantity $$\begin\{aligned\}
    \frac\{d^2 f\}\{dx^2\}
\end\{aligned\}$$ read as \"d square f, d x square\", which denotes the
derivative with respect to $x$ of $\frac\{df\}\{dx\}$. We can also define
higher derivatives such as $\frac\{d^3f\}\{dx^3\}$ and so on.

Note that this function $\frac\{df\}\{dx\}$ doesn't always exist. For
example, consider the function $g(x) = |x|$\

::: marginfigure
![image](figures/Mathematical Foundations/calculus/absolute_value_x.png)\{width="\\linewidth"\}
:::

Let's try evaluating the definition at $x = 0$. We get

$$\begin\{aligned\}
    \frac\{dg\}\{dx\} = \lim_\{\Delta x \to 0\} \frac\{|x + \Delta x| - |x|\}\{\Delta x\}
\end\{aligned\}$$

There's a bit of subtlety here. Note that if we constrain
$\Delta x > 0$, we get $\frac\{dg\}\{dx\} = 1$ and if we constrain
$\Delta x < 0$, we get $\frac\{dg\}\{dx\} = -1$! In practice, what's done
numerically is that we handle points such as $0$ by picking one of these
derivatives. (Formally, all the numbers in the range $[-1, 1]$ are
called *subderivatives* of $|x|$). We say that a function is
differentiable if it has a unique value for this limit at all points. A
function such as $|x|$ is said to be almost-everywhere differentiable.

### Taylor Series

A Taylor series expands a function out in terms of its derivatives. Here
is an example of a Taylor expansion around $0$.

$$\begin\{aligned\}
    f(x) = f(0) + f'(0)x + \frac\{f''(0)^2\}\{2!\}x^2 + \dotsc
\end\{aligned\}$$

We can define the Taylor series about any point $a$ in fact as
$$\begin\{aligned\}
    f(a) &= f(a) + f'(x-a)(x-a) + \frac\{f''(x-a)\}\{2!\} (x-a)^2 + \dotsc
\end\{aligned\}$$

Taylor series are fundamental tools in physics that allow for
approximation of a complex function around a local point. Note that
Taylor series only converge in a region of the approximation point and
not globally typically. One important counterexample to this rule of
thumb is the Taylor series for $e^x$ which converges globally

$$\begin\{aligned\}
    e^x = 1 + x + \frac\{x^2\}\{2!\} + \frac\{x^3\}\{3!\} + \dotsc
\end\{aligned\}$$

### Multivariate Differentiation

Suppose that we have a function of two variables $$\begin\{aligned\}
    f(x, y) &= x^2 + y^2
\end\{aligned\}$$ To find the rate of change of $f$ with respect to either
argument, we use partial derivatives defined as $$\begin\{aligned\}
    \frac\{\partial f\}\{\partial x\} &= \lim_\{\Delta x \to 0\} \frac\{f(x + \Delta x, y) - f(x, y)\}\{\Delta x \}\\
    \frac\{\partial f\}\{\partial y\} &= \lim_\{\Delta y \to 0\} \frac\{f(x, y + \Delta y) - f(x, y)\}\{\Delta y\}
\end\{aligned\}$$

Read $\frac\{\partial f\}\{\partial x\}$ as \"partial f partial x\" or
alternatively as \"doh f doh x\". The idea is that we hold the other
variable constant and take the ordinary derivative with respect to only
one argument.

Let $f: \mathbb\{R\}^N \to \mathbb\{R\}$ be a differentiable function. We
can define partial derivatives $\frac\{\partial f\}\{\partial x_i\}$ with
respect to the different arguments, but is there a way to define a
single joint derivative of $f$? There are many variables here, so which
direction do we take the derivative from? The usual solution is to
define a directional derivative in a direction $\vec\{u\}$. We define the
directional derivative as

$$\begin\{aligned\}
    \nabla_\{\vec\{u\}\}(f) = \lim_\{h \to 0\} \frac\{f(x + h\vec\{u\}) - f(x)\}\{h\}
\end\{aligned\}$$

It's possible to prove (left as an exercise) that

$$\begin\{aligned\}
\nabla_\{\vec\{u\}\}(f) = \frac\{df\}\{dx_1\}u_1 + \cdots + \frac\{df\}\{dx_N\} u_N 
\end\{aligned\}$$

We define the gradient $\nabla f$ as follows

$$\begin\{aligned\}
 \nabla f = \begin\{bmatrix\}
    \frac\{df\}\{dx_1\} \\
    \vdots \\
    \frac\{df\}\{dx_N\} \\
    \end\{bmatrix\} 
\end\{aligned\}$$

Note that then the directional derivative is then simply
$$\begin\{aligned\}
\nabla_\{\vec\{u\}\}(f) = (\nabla f)^T \vec\{u\}
\end\{aligned\}$$ Note that the gradient is the direction in which the
directional derivative is maximized (proof left as an exercise).

Let's now take one more step to generalize. Let
$f: \mathbb\{R\}^N \to \mathbb\{R\}^M$. What is the derivative of $f$? It
turns out that there are a number of reasonable answers, but we will
often find ourselves working with the *Jacobian*. The Jacobian
$\mathcal\{J\}$ is defined as

$$\begin\{aligned\}
 \mathcal\{J\}(f) = \begin\{bmatrix\}
    \frac\{\partial f_1\}\{dx_1\} & \cdots & \frac\{\partial f_1\}\{dx_N\} \\
    & \vdots & \\
    \frac\{\partial f_M\}\{x_1\} & \cdots & \frac\{\partial f_M\}\{x_N\} \\
    \end\{bmatrix\}
\end\{aligned\}$$ Recall that $\frac\{\partial f_i\}\{\partial x_i\}$ is the
partial derivative of function $f_i$ with respect to variable $x_i$.
Here we write $f = (f_1, \dotsc, f_M)$ as $M$ functions of type
$\mathbb\{R\}^N \to \mathbb\{R\}$. Note that
$\mathcal\{J\}(f) \in \mathbb\{R\}^\{M \times N\}$.

## An introduction to integral calculus

Integration is the opposite of differentiation. Let
$f: \mathbb\{R\} \to \mathbb\{R\}$ be a function. We denote the
antiderivative of a function by the notation $$\int f dx$$ The
antiderivative is defined by its relation to the derivative. Broadly
speaking, the antiderivative $\int f dx$ is a function
$\mathbb\{R\} \to \mathbb\{R\}$ such that $$\frac\{d\}\{dx\} \int f dx = f
    \label\{antidereqn\}$$ Antiderivatives are not unique. The reason for
this is the fact that $\frac\{d\}\{dx\}(C) = 0$ where $C \in \mathbb\{R\}$ is
any constant. This means that the antiderivative is only defined up to a
constant. We'll have you work through a few such definitions in the
exercises.

It's possible to compute antiderivatives for simple functions directly
from the defining Equation
[\[antidereqn\]](#antidereqn)\{reference-type="ref"
reference="antidereqn"\}.

### Exercises

1.  Prove that the derivative of $f(x) = e^x$ is $e^x$. Use the fact
    that $$\begin\{aligned\}
            e^x &= 1 + x + \frac\{x^2\}\{2!\} + \frac\{x^3\}\{3!\} + \dotsc
        
    \end\{aligned\}$$

2.  Prove that the antiderivative of $f(x) = x^n$ is
    $\frac\{x^\{n+1\}\}\{n+1\} + C$ by using the defining Equation
    [\[antidereqn\]](#antidereqn)\{reference-type="ref"
    reference="antidereqn"\}.

3.  Prove that the antiderivative of $f(x) = e^x$ is $e^x + C$ by using
    the definiting Equation
    [\[antidereqn\]](#antidereqn)\{reference-type="ref"
    reference="antidereqn"\}. Hint: Consider the Taylor series.
