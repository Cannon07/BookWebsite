# Quantum Mechanics \{#chap:quantum_mechanics\}

------------------------------------------------------------------------

\
**Prerequisites:** [\[chap:pde\]](#chap:pde)\{reference-type="ref+label"
reference="chap:pde"\},
[\[chap:simple_physics\]](#chap:simple_physics)\{reference-type="ref+label"
reference="chap:simple_physics"\}\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------

Quantum mechanics deals with the physics of the very small. Objects like
electrons and photons can behave in ways that are alien to normal
physical intuition. Quantum mechanical systems are described by wave
functions instead of positions, a change which will dramatically alter
the mathematics needed to model these systems.

Although classical mechanics is successful when applied for macroscopic
objects, several experimental observations demonstrate the inadequacy of
classical mechanics in treating microscopic phenomena. For example:

1.  The Rayleigh-Jeans formula for spectral intensity of black body
    radiation, which was based on laws of mechanics, electromagnetic
    theory and statistical thermodynamics failed for short wavelengths
    in what was called as the ultraviolet catastrophe. Max Planck later
    postulated that the oscillating atoms of a black body radiate energy
    only in discrete, i.e. quantized amounts which was found to be in
    agreement with experimental observations
    (Fig. [\[fig:planckslaw\]](#fig:planckslaw)\{reference-type="ref"
    reference="fig:planckslaw"\}).

2.  The interference patterns that arise from light impinging on a
    double-slit experiment, originally done by Young, brought into
    forefront the fact that light and matter can display characteristics
    of both classically defined waves and particles. Young showed by
    means of a diffraction experiment that light behaved as waves. He
    also proposed that different colors were caused by different
    wavelengths of light
    (Fig. [\[fig:youngsslit\]](#fig:youngsslit)\{reference-type="ref"
    reference="fig:youngsslit"\}).

    ::: marginfigure
    ![image](figures/Physics/quantum_mechanics/intro_qm/diffraction pattern.png)\{width="\\linewidth"\}
    :::

3.  The photoelectric effect, explained by Albert Einstein, which is the
    phenomenon of emission of electrons from a metallic surface that is
    subjected to electromagnetic radiation. In case light was only a
    wave, the energy contained in one of those waves would depend only
    on its amplitude, i.e. on the intensity of the light. Other factors,
    like the frequency, should make no difference. However, electron
    emission was found to occur at a threshold frequency (not intensity)
    and the maximum kinetic energy of the emitted electrons was found to
    depend on the frequency of the incident light
    (Fig. [\[fig:photoelectric\]](#fig:photoelectric)\{reference-type="ref"
    reference="fig:photoelectric"\}).

    ::: marginfigure
    ![image](figures/Physics/quantum_mechanics/intro_qm/photoelectric.png)\{width="\\linewidth"\}
    :::

In the following few chapters, we will establish the mathematical
foundations of the theory of quantum mechanics and explain how the shift
from classical to quantum mechanics can help resolve some of these
fundamental questions.

## Mathematical Theory

One of the biggest changes between quantum and classical mechanics is
that we will deal more often with function types since the quantum
mechanical description of a system is given by a *wave function*.

Intuitively, in quantum mechanics, it is no longer reasonable to speak
of hard quantities like \"position\" or \"velocity.\" Using rough
language, we can say that quantum mechanical objects are more accurately
imagined as \"smeared out\". For an electron, rather than a point
particle, we can imagine it as a probability distribution spread out
over space. The takeaway for now is that position types like
$\mathbb\{R\}^3$ are no longer appropriate for describing electrons.
Instead, we want to consider function types like
$\mathbb\{R\}^3 \to \mathbb\{C\}$ (for technical reasons, we want to use the
complex numbers rather than the real numbers).

Giving you a sneak peek of more technical considerations, it turns out
the space of all functions from $\mathbb\{R\}^3 \to \mathbb\{C\}$ is too big
for our purposes. We will more often work in the space of square
integrable functions $L^2(\mathbb\{R\}^3, \mathbb\{C\})$. Recall that a
function $f$ is square-integrable if

$$\begin\{aligned\}
    \int_\{\mathbb\{R\}^3\} |f(x)|^2 dx < \infty
\end\{aligned\}$$

Recall that the space $L^2(\mathbb\{R\}^3, \mathbb\{C\})$ is a Hilbert
space. A wave function $\psi$ is then an element of
$L^2(\mathbb\{R\}^3, \mathbb\{C\})$. To a rough approximation the core
mathematical transformation to go from classical mechanics is that we
make the replacement

$$\begin\{aligned\}
    \mathbb\{R\}^3 \Rightarrow L^2(\mathbb\{R\}^3, \mathbb\{C\})
\end\{aligned\}$$

That is, position vectors are replaced with wave functions. This process
is typically called *quantization*. Much of the mathematical complexity
of quantum mechanics results from the fact that
$L^2(\mathbb\{R\}^3, \mathbb\{C\})$ is a more complicated space that
$\mathbb\{R\}^3$. To make things even more complicated, when we take
actual experimental measurements in the real world, we will end up with
numbers in $\mathbb\{R\}^3$. We need a theory of measurements that can
\"collapse\" our wave functions into more concrete objects.

As an important technical note, we also observe that other spaces
besides $L^2(\mathbb\{R\}^3, \mathbb\{C\})$ can be used to model quantum
systems. We will encounter some other such spaces in our study of spin
and quantum field theories later in the book. The more general point is
that the choice of type to associate with a physical system is a
modeling choice. If you are ever in doubt about the right set of types
to model a physical system, step back and think about which fits the
underlying physics better in the given circumstances.

In this and the following chapters we will introduce you to quantum
mechanics and discuss how differentiable programs can help build
understanding. As always, it is surprisingly useful to keep an eye out
on the types of objects we work with. While physicists classically mix
and match different mathematical objects when describing quantum
mechanical systems, we find that looking at the types provides an
alternative to these traditional methods that can bring its own
insights.

## More About Wave Functions

Let's consider a simple test system with one particle and no spin. Then
let $\psi: \mathbb\{R\}^3 \times \mathbb\{R\} \to \mathbb\{C\}$ be a complex
valued function. For a position $\vec\{x\}$ in space and time $t$,
$\psi(x, t)$ is a complex valued amplitude. We define an associated
function $\rho: \mathbb\{R\}^3 \times \mathbb\{R\} \to \mathbb\{C\}$ as

$$\begin\{aligned\}
    \rho(\vec\{x\}, t) = |\psi(\vec\{x\}, t)|^2
\end\{aligned\}$$

We want to interpret $\rho$ as a probability density function.
Informally we can think of $\rho$ as representing the probability of our
particle being at position $\vec\{x\}$ at time $t$. Note that for $\rho$
to be a probability density function, we need the following
normalization condition to be satisfied.

$$\begin\{aligned\}
\
\int_\{-\infty\}^\{\infty\} |\psi(\vec\{x\}, t)|^2 dx = \int_\{-\infty\}^\{\infty\} \rho(\vec\{x\}, t) dx = 1
\end\{aligned\}$$

That is, at a given time $t$, the probability density $\rho$ must
integrate to probability 1. The condition that $\rho$ forms a
probability distribution automatically guarantees that
$\psi \in L^2(\mathbb\{R\}^3 \times \mathbb\{R\}, \mathbb\{C\})$ (since
$\int_\{\mathbb\{R\}^3 \times \mathbb\{R\}\} |f(x)|^2 dx < \infty$). Another
interesting thing to note though is that by our definition an arbitrary
$g \in L^2(\mathbb\{R\}^3 \times \mathbb\{R\}, \mathbb\{C\})$ can't be a wave
function. Suppose that $g$ satisfies the following equation

$$\begin\{aligned\}
    \int_\{\mathbb\{R\}^3 \times \mathbb\{R\}\} |g(x)|^2 dx = C \neq 1.
\end\{aligned\}$$

$g$ has a bounded square integral, but its norm is not 1. In this case
$\rho_g$ (that is, $\rho_g := |g(x)|^2$) doesn't form a probability
distribution. For this reason, in mathematical introductions to quantum
mechanics its more common to work with the \"projective space\"
$$\begin\{aligned\}
    \mathcal\{P\}L^2(\mathbb\{R\}^3 \times \mathbb\{R\}, \mathbb\{C\}) := \{ f \in L^2(\mathbb\{R\}^3, \mathbb\{R\})| \|f\| = 1\}
\end\{aligned\}$$ We will find it useful to work with arbitrary elements
of $L^2(\mathbb\{R\}^3 \times \mathbb\{R\}, \mathbb\{C\})$ so we often just
identify arbitrary elements $g$ with their normalized version $g/\|g\|$.
Transforming to code,

    def $\psi$(x: $\mathbb\{R\}^3$, t: $\mathbb\{R\}$) -> $\mathbb\{C\}$:
      return C * exp(-m * $\|$x$\|^2$/2)
    assert $\psi$ : $L^2(\mathbb\{R\}^3 \times \mathbb\{R\}, \mathbb\{C\})$

    def pdf(x: $\mathbb\{R\}^3$, t: $\mathbb\{R\}$):
      return $|\psi$(x, t)$|^2$

Note the definition of $\psi$: it's just a regular function. Wave
functions sometimes gain a degree of mystique, but it's useful to see
that we can define them with a few lines of Physika like any other
function. Note also that the type signature of $\psi$ in this definition
is $\mathbb\{R\}^3 \times \mathbb\{R\} \to \mathbb\{C\}$ and not
$L^2(\mathbb\{R\}^3, \mathbb\{R\})$ by default. We use an `assert` statement
to tell Physika that $\psi$ belongs to the more refined type
$L^2(\mathbb\{R\}^3 \times \mathbb\{R\}, \mathbb\{C\})$.

The wave function $\psi$ itself is simply a Gaussian bump function. The
function `pdf` is a convenience function that gives us a way to find the
probability that a particle with wave function $\psi$ is at some
specified $x$ and $t$.

We can generalize this to a formulation for multiple particles in a
straightforward fashion. Let's suppose that we have $N$ particles at
$\vec\{x_1\}, \dotsc, \vec\{x_N\}$. Then we have
$\Phi: \mathbb\{R\}^\{3N + 1\} \to \mathbb\{C\}$ a function where

$$\Phi(\vec\{x_1\}, \dotsc, \vec\{x_N\}, t)$$

is the complex amplitude of a collection of $N$ particles at locations
$\vec\{x_1\}, \dotsc, \vec\{x_N\}$ at time $t$.

## An interlude into types

What are the types associated with quantum mechanics/ Computer
scientists may have noted that $\mathbb\{R\}$ isn't a type that can be
easily implemented in a real programming language since arbitrary
precision can't be exactly represented on a physical device with bounded
memory. That said, numerical analysts have done hard work to make sure
that modern computers have quite good representations of real numbers.
So if we have a function

    def $+$(x: $\mathbb\{R\}$, y: $\mathbb\{R\}$) -> $\mathbb\{R\}$:
      return x + y

there's a reasonable translation of this function into code. But
consider the function

    def $+$(f: $L^2(\mathbb\{R\}, \mathbb\{C\})$, g: $L^2(\mathbb\{R\}, \mathbb\{C\}))$ -> $L^2(\mathbb\{R\}, \mathbb\{R\}, \mathbb\{C\})$:
      return f + g

What does this function mean? $f$ and $g$ are infinite objects by
construction. In one sense, $L^2(\mathbb\{R\}, \mathbb\{C\})$ is \"no
bigger\" than $\mathbb\{R\}$ (that is they have the same cardinality as
sets), so it's not unreasonable that we could create reasonable
implementations for adding $L^2$ functions if we can do so for adding
real numbers. What are some ways this could make sense?

One classical method for representing functions is to reduce a function
to a suitable tuple of real numbers. For example, suppose that our
functions are polynomials

$$\begin\{aligned\}
    f(x) &= a_0 + a_1 x + \dotsc + a_n x^n \\
    g(x) &= b_0 + b_1 x + \dotsc + b_m x^m
\end\{aligned\}$$

We can then add $f$ and $g$ by adding coefficients for corresponding
terms $$\begin\{aligned\}
    (f + g)(x) &= (a_0 + b_0) + (a_1 + b_1)x + \dotsc
\end\{aligned\}$$ In this case we can implement `add_l2` by using list
types

    def $+$(f: [$\mathbb\{R\}$], g: [$\mathbb\{R\}$]) -> [$\mathbb\{R\}$]:
      return [fi + gi for (fi, gi) in zip(f, g)]

(Assume that `zip` intelligently handles lists of different lengths.)
There's also no reason you have to use polynomials as your basis here.
You could very well use Fourier coefficients or another more efficient
basis so you can represent a richer class of functions.

Of course, all this is very classical, but since we're working with deep
networks, we also have access to very powerful representations that were
not classically accessible. Consider the following definition of $f$

    def h(x: $\mathbb\{R\}$, N: $\mathbb\{N\}$) -> $\mathbb\{R\}$:
      input = x
      for i in range(N):
        wi, bi: $\mathbb\{R\}$
        input = ReLU(wi*x + bi)
      return input

Note that `h` can represent an extremely rich class of functions. Why?
`h` is a dense network that can be arbitrarily deep. In particular,
since `wi, bi` are learnable variables, in principle, arbitrary elements
of $L^2(\mathbb\{R\}, \mathbb\{R\})$ could be represented by `h` (there are
some considerably challenging questions of convergence here, but we
won't delve into those.) In this case you can define

    def add(f: $\mathbb\{R\}$ -> $\mathbb\{R\}$, g: $\mathbb\{R\}$ -> $\mathbb\{R\}$) -> ($\mathbb\{R\}$ -> $\mathbb\{R\}$):
      return $\lambda$ x: f(x) + g(x)

Arguably, this function is as close to a faithful implementation of
addition on $L^2(\mathbb\{R\}^3, \mathbb\{C\})$ as is possible on a modern
computer. A theme we will return to often is that differentiable
programming provides powerful tools for handling sophisticated function
spaces that weren't accessible to past analytical analyses. By slightly
broadening the class of functions we consider past the traditional
collections of bases, we open up a variety of doors as we shall see in
the remainder of the book.
