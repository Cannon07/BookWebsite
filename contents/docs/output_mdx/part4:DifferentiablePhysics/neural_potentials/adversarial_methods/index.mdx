# Adversarial Attacks \{#chap:ani\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:molecular_hamiltonian\]](#chap:molecular_hamiltonian)\{reference-type="ref+label"
reference="chap:molecular_hamiltonian"\},\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------

In this chapter, we describe how uncertainty quantification methods
based on ensembles of differentiable models and on customized loss
functions, including mean-variance estimation enable gradient-based
active learning to systematically improve machine learned potentials.
Because uncertainty metrics are differentiable end-to-end with respect
to model inputs, it is possible to shift input atomic positions towards
regions of low energy and high uncertainty, so they can be labeled with
new quantum chemical simulations [@wang2020active], [@ang2021active],
[@schwalbe2021differentiable].

Adversarial attacks on uncertainty allow exploring the phase space more
efficiently than traditional approaches and helps train accurate and
generalizable surrogate functions.

The loss is given by $$\begin\{aligned\}
\mathcal\{L\} &= \frac\{1\}\{N\} \sum_\{i=1\}^N [\alpha_E \|E_i -\hat\{E\}_i\|^2 + \alpha_F \|F_i - \hat\{F\}_i\|^2]
\end\{aligned\}$$ We can compute the mean and standard deviation of the
energy as $$\begin\{aligned\}
\bar\{E\}(X) &= \frac\{1\}\{M\} \sum_\{m=1\}^M \hat\{E\}^\{(m)\}(X) \\
\sigma_E^2(X) &= \frac\{1\}\{M-1\} \|\hat\{E\}^\{(m)\}(X) - \bar\{E\}(X)\|^2
\end\{aligned\}$$ Similar calculations can be performed for forces. New
adversarial geometries are selected by perturbing the input system
$$\begin\{aligned\}
\min_\theta \mathbb\{E\}_\{(X, E, F) \sim \mathcal\{D\}\} \left [ \max_\{\delta \in \Delta\} \mathcal\{L\}(X_\delta, E_\delta, F_\delta, \theta) \right ]
\end\{aligned\}$$

where $\Delta$ is a set of potential perturbations usually defined as
$$\begin\{aligned\}
\Delta &= \{ \delta \in \mathbb\{R\} | \|\delta\|_p \leq \epsilon \}
\end\{aligned\}$$ Adversarial updates are computed by $$\begin\{aligned\}
X_\delta &= (Z, R + \delta)
\end\{aligned\}$$ $$\begin\{aligned\}
\max_\{\delta \in \Delta\} \mathcal\{L\}_\{adv\}(X, \delta, \theta) &= \max_\{\delta \in \Delta\} \sigma^2_F(X_\delta)
\end\{aligned\}$$ We can also Boltzmann-weight to obtain $$\begin\{aligned\}
\max_\{\delta \in \Delta\} \mathcal\{L\}_\{adv\}(X, \delta, \theta) &= \max_\{\delta \in \Delta\} p(X_\delta) \sigma^2_F(X_\delta)
\end\{aligned\}$$ This adversarial loops allows construction of perturbed
geometries that have low energy by construction but high uncertainty.
Reparameterizing the force field including these new examples can lead
to more robust behavior.
