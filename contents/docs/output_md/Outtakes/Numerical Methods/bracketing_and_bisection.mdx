# Root Finding: Bracketing and Bisection

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:calculus\]](#chap:calculus)\{reference-type="ref+label"
reference="chap:calculus"\},
[\[chap:optimization\]](#chap:optimization)\{reference-type="ref+label"
reference="chap:optimization"\}\
**Difficulty Level:** \*\

------------------------------------------------------------------------

The most basic numerical operation involves finding solutions to
equations. This problem aims to find the value of $x$ (root) at which a
function, $f(x)$ attains the value $0$, i.e. $f(x) = 0$. For simple
functions, polynomials, there exists analytical ways of finding the
roots of the function. For many variables, this generalizes to
$\mathcal\{F\}(\vec{x}) = 0$.

Despite the simple formulation, finding roots to general non-linear
equations is analytically intractable and numerical methods are needed
to solve them. Traditionally, there are a few ways to approach
root-finding:

1.  Graphical Methods

2.  Bracketing Methods

3.  Bisection Methods

Graphical methods plot functions to inspect for roots visually by eye.
In bracketing methods of root-finding, roots are located within an
interval prescribed by a lower and an upper bound. In contrast,
bisection methods require only a single starting value or two starting
values that do not necessarily bracket the root. In bracketing methods,
the estimate of the root gets better with every iteration. This cannot
be ensured in the case of bisection methods. However, when bisection
methods converge, they converge much faster than the bracketing methods.

Bisection methods rely on two initial guesses to form the bracket
containing the root. For well-posed problems, the bracketing methods
always work but converge slowly. Initial guesses may naturally arise
from the physical context you are analyzing. However, in other cases,
good initial guesses may not be obvious. In such cases, automated
approaches to obtain guesses would be useful. The following section
describes one such approach, the incremental search.

## Graphical Methods

:::marginfigure
![image](figures/part1b/bracketing_and_bisection/graphical.PNG)\{width="1.2in"\}
[]\{#fig:3 label="fig:3"\}
:::

A simple method for obtaining an estimate of the root of the equation
$f(x)$ = 0 is to make a plot of the function and observe where it
crosses the x-axis. This point, which represents the x value for which
$f(x)$ = 0, provides a rough approximation of the root. Graphical
techniques are of limited practical value because they are not very
precise. However, graphical methods can be utilized to obtain rough
estimates of roots. These estimates can be employed as starting guesses
for numerical methods discussed next.

## Bracketing Methods

These methods rely on two initial guesses to form the bracket containing
the root. For well-posed problems, the bracketing methods always work
but converge slowly. Initial guesses may naturally arise from the
physical context you are analyzing. However, in other cases, good
initial guesses may not be obvious. In such cases, automated approaches
to obtain guesses would be useful. The following section describes one
such approach, the incremental search.

## Incremental Search

In general, it can be observed that, a root can be found in an interval
from $x_i$ to $x_f$ for the function $f(x)$, if $f(x_l)$ and $f(x_u)$
have opposite signs, that is,

$$\begin{aligned}
f(x_l)f(x_u) &< 0
\end{aligned}$$

Incremental search methods capitalize on the observation by locating an
interval where the function changes sign. A potential problem with an
incremental search is the choice of the increment length. If the length
is too small, the search can be very time consuming. On the other hand,
if the length is too great, there is a possibility that closely spaced
roots might be missed. The problem is compounded by the possible
existence of multiple roots.

:::marginfigure
![image](figures/part1b/bracketing_and_bisection/Increment.png)\{width="2.5in"\}
:::

A graphical depiction of incremental search with six intervals is shown
in the Figure [\[fig:2\]](#fig:2)\{reference-type="ref"
reference="fig:2"\}. It can be observed that, since the interval is too
wide, the roots between $x_0$ and $x_1$ intervals are missed. To
overcome this, smaller interval sizes can be used. In a similar fashion,
this method fails when there are multiple roots within an interval.

:::example
Consider polynomial: $x^3 - 3.7x^2 + 4.54 x - 1.848$, which has three
real roots. Let's start with a wide search space between $-100$ and
$100$ and a discretization of 0.4. Note that this will lead to a bracket
of width 0.4. The output of this snippet is shown on the right. Register
the time that this algorithm took to converge to an accuracy of 0.4. As
an exercise, lower the width to 0.04 and note down the time it takes.

```python
l = 0.04
# Incremental search                                   
x = range(-100, 100+l, l)                              
f = x**3 - 3.7 * x**2 + 4.54 * x - 1.848               

#xb is empty unless sign change detected               
nb = 0                                                 
xb = []                                                
for k in range(len(x)-1):                              
  if sign(f[k]) != sign(f[k+1]):                       
    nb += 1
    xb.append((nb, x[k], x[k+1]))                      
    
if len(xb) == 0:                                       
  print("No brackets found. Check interval or increase granularity.")
else:
  print("Number of brackets found: %d" % nb)           
  print("Brackets Found:")                             
  print(xb)
```
:::

:::margintable
**Output: Incremental Search**

    number of brackets found: 3
    Brackets found:
        1.0800    1.1200
        1.1600    1.2000
        1.4000    1.4400
:::

## Bisection Method

The bisection method is a variation of the incremental search method in
which the interval is always divided in half. If a function changes sign
over an interval, the function value at the midpoint is evaluated. The
location of the root is then determined as lying within the subinterval
where the sign change occurs. The subinterval then becomes the interval
for the next iteration. The process is repeated until the root is known
to the required precision.

:::marginfigure
![image](figures/part1b/bracketing_and_bisection/Bisection.png)\{width="2.5in"\}
:::

To decide when to terminate the algorithm, an error estimate
*Approximate Percent Relative Error* is defined as follows:

$$\begin{aligned}
|\epsilon_{a}| = \left |{\frac{x_r^{new} - x_r^{old}}{x_r^{new}}}\right | 
\end{aligned}$$

where $x_r^{new}$ is the root for the present iteration and $x_r^{old}$
is the root from the previous iteration. When $|\epsilon_{a}|$ becomes
less than a pre-specified stopping criterion $\epsilon_s$, the
computation is terminated.

::::example
Let's go back to the same polynomial and compare the times between the
two algorithms for the same accuracy. Note that using the bracketing
method, you will always be able to narrow down to only one root (there
may be multiple).

:::margintable
**Output: Bisection Method**

    Bracket found using the Bisection method:
        1.0800    1.1200
:::

```python
l = 0.04
# Incremental search                                   
x = range(-100, 100+l, l)                              
f = x**3 - 3.7 * x**2 + 4.54 * x - 1.848               

index_l = 0
index_u = len(x)-1                                     

while (index_u - index_l > 1):                         
  index_mid = int(floor((index_u+index_l)/2.0))        
  f_mid = f[index_mid]
  if f_mid*f[index_l] < 0:
    index_u = index_mid                                
  elif f_mid*f[index_u] < 0:                           
    index_l = index_mid                                
  
print('Bracket found using the Bisection method:')     
print([x[index_l], x[index_u]])   
```
::::

:::example
Find the poles of $f(x) = x^3 - x - 1$ using the bisection nethod with
an initial guess of bracket \[1,2\].

   **i**     **\[$a_i,b_i$\]**           **$f(a_i)$**            **$f(b_i)$**        **$\frac{a_i+b_i}{2}$**   **$f(\frac{a_i+b_i}{2})$**
  ------- ------------------------ ------------------------ ----------------------- ------------------------- ----------------------------
    $0$           \[1,2\]                     -1                       5                       1.5                       0.875
    $1$          \[1,1.5\]                    -1                     0.875                    1.25                     -0.296875
    $2$         \[1.25,1.5\]              -0.298675                  0.875                    1.375                    0.2246093
    $3$        \[1.25,1.375\]             -0.298675               0.22460937                 1.3125                   -0.05151367
    $4$       \[1.3125,1.375\]           -0.051513672             0.22460937                 1.34375                   0.0826111
    $5$              .                        .                        .                        .                          .
    $.$              .                        .                        .                        .                          .
   $14$    \[1.324707,1.3247681\]   -4.659$\times 10^{-5}$   2.137$\times 10^{-4}$          1.3247375            8.335$\times 10^{-5}$
   $15$    \[1.324707,1.3247375\]   -4.659$\times 10^{-5}$   8.335$\times 10^{-5}$          1.3247223            1.848$\times 10^{-5}$

After 15 iterations, the root found is $x = 1.3247223$. The bisection
algorithm's interval reduces by a factor of 2 at every iteration,
enabling it to converge to the root a lot quicker. After k iterations,
the level of accuracy reached is given by the width of the bracket.
$$\text{Accuracy}  = \frac{\text{search space width}}{2^k}$$

After 15 iterations, the level of accuracy is given by
$\frac{1}{2^{15}} = 0.00003051757$. To attain this level of accuracy for
incremental Search, the interval width would have to be about
$3*10^{-5}$; i.e. more than 33000 increments per unit interval.
:::

In summary, incremental search is capable of finding multiple roots but
usually takes a longer time than the bisection method (for same
accuracy). The bisection method can bracket only one root but is in
general much faster than the incremental search.

## Special cases

Special cases for root finding are associated with either multiple roots
or discontinuous functions, which are depicted in the figure on the
right.

:::marginfigure
![image](figures/part1b/bracketing_and_bisection/exception.png)\{width="1.2in"\}
:::

-   Multiple roots can occur when the function is tangential to the x
    axis. For this case, although the end points are of opposite signs,
    there are an even number of axis interceptions for the interval.

-   Discontinuous functions where end points of opposite sign bracket an
    even number of roots. Special strategies are required for
    determining the roots for these cases.

For these cases, graphical methods are critical to understand the nature
of the function, for ensuring that the root finding algorithm is given
good initial guesses. Note that the same search strategies work but a
more careful analysis becomes important.

## Exercises

1.  TODO
