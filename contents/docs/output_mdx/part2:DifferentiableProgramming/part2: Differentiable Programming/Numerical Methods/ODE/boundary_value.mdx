# The Finite Difference Method \{#chap:linear_boundary\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:linear_systems\]](#chap:linear_systems)\{reference-type="ref+label"
reference="chap:linear_systems"\}\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------

In this chapter we learn how to implement the finite-difference method
and study how derivative boundary conditions are incorporated into the
finite-difference method. By the end of the chapter, you will know how
to solve 2nd-order nonlinear ODEs with the finite-difference method by
using root-location methods for systems of nonlinear algebraic
equations.

## Finite Difference Method

A boundary value problem is a differential equation together with a set
of additional constraints, called the boundary conditions. A solution to
a boundary value problem is a solution to the differential equation
which also satisfies the boundary conditions. In the finite difference
method, finite differences are substituted for the derivatives in the
original equation. Thus, a linear differential equation is transformed
into a set of simultaneous algebraic equations which can then be solved.

Consider a pod of mass $m$ traveling inside a vacuum tube which is 1
mile in length. The pod experiences a drag force proportional to its
velocity (by factor $k$) due to the magnets used to levitate and brake.
The vacuum tube is maintained at very low pressure (almost close to
vacuum) and hence the drag due to air is almost zero. A pusher attached
to the pod provides a constant propelling force $F$ to move the pod in
the tube. Friction due to wheels is neglected as the pod is assumed to
levitate. This setup can be modeled as $$\begin\{aligned\}
m\dfrac\{d^2x\}\{dt^2\} = F - k\dfrac\{dx\}\{dt\}
\end\{aligned\}$$

::: marginfigure
![image](figures/part1b/boundary_value/Hyperloop_Finite_approach.png)\{width="2.4in"\}
:::

As shown in Figure [\[fd:fig:1\]](#fd:fig:1)\{reference-type="ref"
reference="fd:fig:1"\}, the solution domain is first divided into a
series of time steps. At each time step, finite difference
approximations can be written for the derivatives in the equation. For
example, at time step $i$, the second and first derivative can be
represented by $$\begin\{aligned\}
\frac\{d^2x\}\{dt^2\} &= \dfrac\{x_\{i-1\}-2x_i+x_\{i+1\}\}\{\Delta t^2\}\\
\frac\{dx\}\{dt\} &=  \dfrac\{x_\{i+1\}-x_i\}\{\Delta t\};
\end\{aligned\}$$

This approximation can be substituted into the governing equation to
give $$\begin\{aligned\}
m\left (\dfrac\{x_\{i-1\}-2x_i+x_\{i+1\}\}\{\Delta t^2\}\right) &= F - k\left (\dfrac\{x_\{i+1\}-x_i\}\{\Delta t\}\right )\\
-mx_\{i-1\} + (k\Delta t + 2m)x_i - (k\Delta t + m)x_\{i+1\} &= -F\Delta t^2
\end\{aligned\}$$

If the domain is divided into $n$ time steps then $x_0$ and $x_n$ values
are specified by the boundary conditions. Therefore, the problem reduces
to solving $n-1$ simultaneous linear algebraic equations for the $n-1$
unknowns. The time steps are numbered consecutively, and since each
equation consists of a time step $(i)$ and its adjoining neighbors
($i-1$ and $i+1$), the resulting set of linear algebraic equations will
be tridiagonal.\

## Tridiagonal Matrix Algorithm

This method, also known as the Thomas algorithm, is a simplified form of
Gaussian elimination that can be used to solve tridiagonal systems of
equations. A tridiagonal system for $n$ unknowns may be written as

$$\begin\{aligned\}
a_ix_\{i-1\} + b_ix_i + c_ix_\{i+1\} = d_i
\end\{aligned\}$$ where $a_1 = 0$ and $c_n = 0$.

::: margintable
$$\begin\{bmatrix\}
b_1 & c_1 &  &  & 0\\ 
a_2 & b_2 & c_2 &  & 0 \\ 
  & a_3 & b_3 & \ddots & \\
 &  & \ddots & \ddots & c_\{n-1\}\\
0  &  &  & a_n & b_n
\end\{bmatrix\} 
\left \{
\begin\{tabular\}\{c\}
$x_1$ \\
$x_2$ \\
$x_3$  \\
$\vdots$ \\
$x_n$
\end\{tabular\}
\right \}
=
\left \{
\begin\{tabular\}\{c\}
$d_1$ \\
$d_2$ \\
$d_3$ \\ 
$\vdots$\\
$d_n$
\end\{tabular\}
\right \}$$
:::

For such systems, the solution can be obtained in *O(n)* operations
instead of *$O(n^3)$* required by Gaussian elimination. A first sweep
eliminates the $a_i$'s, and then an (abbreviated) backward substitution
produces the solution.\
The equations to be solved are: $$\begin\{aligned\}
 b_0 x_0 + c_0x_1 = d_0 \qquad &i = 0\\
a_ix_\{i-1\} + b_ix_i + c_ix_\{i+1\} = d_i \qquad &i = 1,....,n-2\\
a_\{n-1\}x_\{n-2\} + b_\{n-1\}x_\{n-1\} = d_\{n-1\}\qquad  &i = n - 1
\end\{aligned\}$$ Multiplying the first equation with the fraction
($a_1/b_0$) and subtracting it from the second equation $(i = 1)$ to
eliminate $x_0$ gives $$\begin\{aligned\}
\left (b_1 - \frac\{a_1\}\{b_0\}c_0\right )x_1 + c_1x_2 = d_1 - \frac\{a_1\}\{b_0\}d_0
\end\{aligned\}$$

Next modify the third equation $(i = 2)$ with the initial second
equation to eliminate $x_1$. This procedure is repeated until the
$(N-1)^\{th\}$ row; the (modified) $(N-1)^\{th\}$ equation will involve only
one unknown, $x_\{N-1\}$. This may be solved for and then used to solve
the $(N-2)^\{th\}$ equation, and so on until all of the unknowns are
solved for. The coefficients of the modified equations can be defined as
follows: $$\begin\{aligned\}
b_i^\{'\} &= b_i - \left (\dfrac\{a_i\}\{b_\{i-1\}\}\right )c_\{i-1\}\\
c_i^\{'\} &= c_i\\
d_i^\{'\} &= d_i - \left (\dfrac\{a_i\}\{b_\{i-1\}\}\right )d_\{i-1\}
\end\{aligned\}$$

where the system is redefined as: $$\begin\{aligned\}
b'_ix_i + c_ix_\{i+1\} &= d'_i \ \mathrm\{for\}\ i = 1,\dotsc,N-2\\
b'_\{N-1\}x_\{N-1\} &= d'_\{N-1\} \ \mathrm\{for\}\  i = N-1
\end\{aligned\}$$ The last equation involves only one unknown. Solving it
in turn reduces the next last equation to one unknown, so that this
backward substitution can be used to find all of the unknowns:
$$\begin\{aligned\}
b'_ix_i + c_ix_\{i+1\} &= d'_i \  \mathrm\{for\}\  i = n-1,n-2,\dotsc,1
\end\{aligned\}$$ Let us now consider how to implement the Tridiagonal
matrix algorithm in Physika

``` \{.python language="python"\}
def tridiagonal(F: $\mathbb\{R\}$, m: $\mathbb\{R\}$, k: $\mathbb\{R\}$, (xi, xe) : $\mathbb\{R\}^2$, (ti,te): $\mathbb\{R\}^2$, dt: $\mathbb\{R\}$):
  N = (te - ti)/dt- 1
  a = -m*ones(N)
  b = (k*dt + 2*m)*ones(N)
  c = -(k*dt + m)*ones(N)
  d = (-F*dt$^2$)*ones(N)
  d[0] = -F*dt$^2$ + m*xi
  d[N-1] = -F*dt$^2$ + xe*(k*dt + m)
  x = ones(N)

  for i:
    b[i] = b[i] - (a[i]/b[i-1])*c[i-1]
    d[i] = d[i] - (a[i]/b[i-1])*d[i-1]  
  x[N-1] = d[N-1]/b[N-1] # Perform the backsubstitution
  for j = N-2:-1:0:
    x[j] = (d[j] - x[j+1]*c[j])/b[j]
  x
```

We have implemented this equation for the specific equation
$$\begin\{aligned\}
    m\frac\{d^2x\}\{dt^2\} &= f - k \frac\{dx\}\{dt\}.
\end\{aligned\}$$ This implementation will not directly generalize to
higher order equations, which will require a more complex equation
solution method.

## Derivative Boundary Conditions

There are three types of boundary conditions commonly encountered in the
solution of ordinary or partial differential equations:

-   *Dirichlet boundary condition*: It specifies the values that a
    solution needs to take on along the boundary of the domain.

-   *Neumann boundary condition*: It specifies the values that the
    derivative of a solution is to take on the boundary of the domain.

-   *Robin boundary condition*: It is a specification of a linear
    combination of the values of a function and the values of its
    derivative on the boundary of the domain.

The derivation in the previous section can be modified to work for
Neumann boundary conditions.

## The Finite Difference Method for Nonlinear ODEs

For nonlinear ODEs, the substitution of finite differences yields a
system of nonlinear simultaneous equations. Thus, the most general
approach to solving such problems is to use root-location methods for
systems of equations such as the Newton-Raphson method which will be
introduced in next lecture. An adaptation of successive substitution can
sometimes provide a simpler alternative.

Consider the tube problem solved above. If the pressure in the tube is
not close to vacuum then the air drag comes into picture.
$$\begin\{aligned\}
m\dfrac\{d^2x\}\{dt^2\} = F - k\dfrac\{dx\}\{dt\} - \dfrac\{1\}\{2\}\left (\dfrac\{dx\}\{dt\}\right )^2C_DA
\end\{aligned\}$$ We can convert this differential equation into algebraic
form by writing it for a time step $i$ and substitute for the second
derivative. $$\begin\{aligned\}
m\left (\dfrac\{x_\{i-1\}-2x_i+x_\{i+1\}\}\{\Delta t^2\}\right) = F - k\left (\dfrac\{x_\{i+1\}-x_i\}\{\Delta t\}\right )-\frac\{1\}\{2\}\left (\dfrac\{x_\{i+1\}-x_i\}\{\Delta t\}\right)^2C_DA
\end\{aligned\}$$ For routinely encountered problems in engineering and
science, if we assume that the unknown nonlinear term is equal to its
value from the previous iteration, then the equation can be solved and
iterate until the process converges to an acceptable tolerance. Although
this approach will not work for all cases, it converges for many ODEs
derived from physically based systems.
