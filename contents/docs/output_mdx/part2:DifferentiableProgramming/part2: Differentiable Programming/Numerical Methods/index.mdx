# Monte Carlo Methods \{#chap:monte_carlo\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:calculus\]](#chap:calculus)\{reference-type="ref+label"
reference="chap:calculus"\}\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------

When analytical methods fail to model complex spaces, Monte Carlo
methods will be needed to properly sample the phase space. Monte Carlo
methods use probabilistic samples to explore a high dimensional space.
These techniques prove valuable when generating samples from a complex
distribution or approximating a high dimensional integral.

The standard Monte Carlo methods use a simple, random sampling scheme in
addition to a accept-reject formulation to provide a way for the Monte
Carlo scheme to minimize the "energy" of the solution. Various
implementations of Monte Carlo exist that are best suited to different
types of parameter spaces and target distributions.

Underlying distributions for interacting real systems are often unknown;
in general we are not able to make use of the analytical machinery
afforded by non-interacting systems and instead need to rely on brute
force numerical computing. The most computationally taxing task tends to
be computing the partition function, as it requires delineating the full
space of possible states and performing a high-dimensional integral. In
this chapter, we explore various stochastic sampling techniques for
achieving this that are collectively known as Monte Carlo methods.

## Monte Carlo

Monte Carlo techniques, named for the casino town in Monaco, rely on
random samples rather than deterministic techniques to sample the space
of interest. The simplest random sampler to integrate draws from a
uniform distribution in order to calculate a quantity such as the
average energy,

$$\begin\{aligned\}
\langle E \rangle & = \int \frac\{E(\phi) \exp[-\beta E(\phi)]\}\{Q\} 
\end\{aligned\}$$

The probability distribution, $\exp[-\beta E(\phi)]$ is sharply peaked
and states with $E <\sim \langle E \rangle$ dominantly contribute, which
is a very small fraction of the whole phase space. Thus, standard
uniform sampling Monte Carlo, which is homogeneous over the phase space
fails.

## Importance Sampling

The limitations of uniform sampling can be partially overcome by the
technique of *importance sampling*. The whole challenge is associated
with generating configurations, $\phi$ such that they represent the
distribution, $$\begin\{aligned\}
p(\phi) = \int \frac\{\exp[-\beta E(\phi)]\}\{Q\}
\end\{aligned\}$$ It is nearly impossible to generate these configurations
from scratch as we do not know how to do this! (except in some limited
simple cases where you can enumerate the possible configurations.) The
core method, behind almost all of the modern Monte Carlo simulation
technology, is based on a proposal by Metropolis, Rosenbluth and Teller,
where we modify existing configurations in small steps, called Monte
Carlo update steps. This generates a Markov chain of configurations
wherein we sample using a non-uniform distribution (e.g. sample low
energy configurations) and then correct for this nonuniformity in our
calculation. Consider the case of estimating the mean of a probability
distribution $P(x)$ $$\begin\{aligned\}
     \mu = \int xP(x)dx\,.
 
\end\{aligned\}$$ By our previous prescription, the Monte Carlo estimator
would be: $$\begin\{aligned\}
    \mathbf\{E\}[X] = \frac\{1\}\{N\}\sum_1^N X P(X)\,,
\end\{aligned\}$$ where the RV $X$ is drawn uniformly from the domain of
$P$.

Note that if we multiply the integrand by $\frac\{q(x)\}\{q(x)\}=1$, we can
rewrite the mean in terms of the expectation value under the
distribution $q(x)$: $$\begin\{aligned\}
\mu = \int x\frac\{P(x)q(x)\}\{q(x)\}dx=\mathbf\{E\}_q\left[\frac\{xP(x)\}\{q(x)\}\right]\,,
\end\{aligned\}$$ which shows us exactly how to construct the importance
sampled estimator:
$$\mu = \frac1N\sum_1^NX\frac\{P(X)\}\{q(X)\}\text\{ where \} X\sim q\,.$$

## Markov Chains

A Markov chain is a stochastic model consisting of transitional
probabilities between states that depend only on the system's current
state. In other words, such a model can be fully specified by its
*transition matrix* $P$, defined such that $P_\{ij\}$ is the probability
of moving to state $j$ given that the system is currently in state $i$.
Since row $i$ must contain probabilities for every possible transition
from state $i$, it follows that each row of $P$ must sum to 1, a
property known as *right stochasticity*.

::: marginfigure
![image](figures/part1b/monte_carlo/MC1_0.png)
:::

Note that by convention, Markov chain transitions are defined by the
multiplication of a row vector state with the transition matrix:
$$\vec s_\{i+1\} = \vec s_i P\,.$$ If $\vec s_i$ is an eigenvector of $P$,
then $\vec s_\{i+1\}=\vec s$ and $\vec s$ represents a *stationary
distribution* of the Markov chain represented by $P$. When using Markov
chains in Monte Carlo sampling of the complicated,
difficult-to-normalize distributions often of interest in parameter
estimation problems, the goal is to construct a Markov chain whose
stationary distribution is the target distribution. Then, by using the
Markov process to explore the parameter space and saving points at every
iteration, we can build up a histogram of visited points that will
converge to that distribution.

## Metropolis-Hastings Monte Carlo Simulation

A commonly used Monte Carlo scheme is *Metropolis-Hastings Monte Carlo*,
or MHMC. The basic algorithm is as follows:

1.  Starting from state $\theta$, randomly create a new trial state
    $\theta^*$ from the proposal distribution.

2.  The probability $\alpha$ of choosing this new state is given by:
    $$\alpha = \exp[\beta(E_\{\theta\} - E_\{\theta^*\})]$$

3.  If $\alpha \geq 1$, set $\theta$ to $\theta^*$

4.  If $\alpha < 1$, select a uniform random number $A$ between 0 and 1,
    and only change the state from $\theta$ to $\theta^*$ if
    $A < \alpha$

We can turn this description into a Physika sketch

``` \{.python language="python"\}
def metropolis_hastings($\theta: \mathbb\{R\}$, $q: \mathbb\{R\} \to \mathbb\{R\}$, $\beta: \mathbb\{R\}$, N : $\mathbb\{N\}$):
  $E_\theta$ = E($\theta$)
  for i < N:
    $\theta^*$ = $q(\theta)$
    $E_\{\theta^*\}$ = E($\theta^*$)
    $\alpha$ = exp($\beta(E_\theta - E_\{\theta^*\}$)
    if $\alpha$ >= 1:
      $\theta$ = $\theta^*$
    else:
      A = uniform(0, 1)
      if A < $\alpha$:
        $\theta$ = $\theta^*$
```

A common use case is to explore a potential energy landscape in some
high-dimensional configurational space, where it is relatively
straightforward to compute the energy of a given state (which can be
related to its probability by a Boltzmann weight), but difficult to
enumerate the full state space and hence normalize the distribution.

::: marginfigure
![image](figures/part1b/monte_carlo/theta_t_mc.png)\{width="\\linewidth"\}
![image](figures/part1b/monte_carlo/pdf_mc.png)\{width="\\linewidth"\}
![image](figures/part1b/monte_carlo/autocorr_mc.png)\{width="\\linewidth"\}
:::

There are many caveats to Monte Carlo simulations. Care has to be taken
when determining whether you have fully sampled the distribution.
Adaptive methods for randomly selecting trial states that do not result
in too many instances of rejections or too small of moves must be
established. Calculating certain averages can be difficult when the
simulation needs to explore rare regions of phase space to accurately
evaluate the average. Therefore, one must ensure the moves are able to
get out of deep wells. Importantly, it must be ensured that the
simulation are not biased to any region of phase space (for satisfying
the ergodic hypothesis). Monte Carlo simulation is generally very
adaptable to different models and is very simple to implement.

### Hamiltonian Monte Carlo

Hamiltonian Monte Carlo is a special case of MHMC that borrows concepts
from physics to improve (i.e. reduce) autocorrelation between samples.
The basic concept is that rather than randomly drawing new states from
some proposal distribution, the proposals are generated by evolving a
state according to dynamics as governed by Hamilton's equations.
Remember that the Hamiltonian $H(x, p)$ is defined as the sum of the
potential and kinetic energies: $$\begin\{aligned\}
H(x, p) = U(x) + K(p)
\end\{aligned\}$$ The equations of motion are given by: $$\begin\{aligned\}
\frac\{\partial x_i\}\{\partial t\} &= \frac\{\partial H\}\{\partial p_i\} = \frac\{\partial K( p)\}\{\partial p_i\} \\
\frac\{\partial p_i\}\{\partial t\} &= -\frac\{\partial H\}\{\partial x_i\} = - \frac\{\partial U( x)\}\{\partial x_i\}
\end\{aligned\}$$

### Time integration by the Leap Frog method

The phase-space integration is analogous to the Velocity-Verlet
algorithm utilized in molecular dynamics simulations and proceeds as
follows:

1.  Take a half step in time to update the momentum variable
    $$\begin\{aligned\}
        p_i(t + \delta/2) = p_i(t) - (\delta /2)\frac\{\partial U\}\{\partial x_i(t)\}
        
    \end\{aligned\}$$

2.  Take a full step in time to update the position variable:
    $$\begin\{aligned\}
        x_i(t + \delta) = x_i(t) + \delta \frac\{\partial K\}\{\partial p_i(t + \delta/2)\}
        
    \end\{aligned\}$$

3.  Take the remaining half step in time to finish updating the momentum
    variable $$\begin\{aligned\}
        p_i(t + \delta) = p_i(t + \delta/2) - (\delta/2) \frac\{\partial U\}\{\partial x_i(t+\delta)\}
        
    \end\{aligned\}$$

In a canonical ensemble, any energy function $E(\theta)$ over a set of
variables $\theta$, we can define the corresponding canonical
distribution as: $p(\theta) = \frac\{1\}\{Q\}e^\{-E(\theta)\}$ where we simply
take the exponential of the negative of the energy function. The
partition function, Q will cancel out when taking ratios. The canonical
distribution for the Hamiltonian dynamics energy function is
$$\begin\{aligned\}
p( x, p) & \propto e^\{-\beta H( x, p)\} \nonumber \\ & = e^\{-\beta [U( x) + K( p)]\} \nonumber = e^\{-\beta U( x)\}e^\{-\beta K( p)\} \nonumber \\ & \propto p( x)p( p)
\end\{aligned\}$$

The canonical distribution for $x$ and $p$ factorizes. This means that
the two variables are independent (non-interacting degrees of freedom).
Therefore, using Hamiltonian dynamics, we can sample from the joint
canonical distribution and simply ignore the momentum contributions. For
a given set of initial conditions, Hamiltonian dynamics will follow
contours of constant energy in phase space. Therefore, we must randomly
perturb the dynamics so as to explore all of phase space (e.g. all
possible configurations in an Ising Model). We can choose any
distribution from which to sample the momentum variables. A common
choice is to use a standard normal distribution. The acceptance
criterion is constructed the same way as for MHMC, but we now
specifically stipulate that the acceptance probability goes as a
Boltzmann weight of the Hamiltonian and not just of the energy.

Combining these steps, sampling random momentum, followed by Hamiltonian
dynamics and Metropolis acceptance criterion defines the HMC algorithm
for drawing M samples from a target distribution:

1.  set t = 0

2.  generate an initial position state $x^\{(0)\}$

3.  repeat until $t = M$

    -   set t = t+1

    -   sample a new initial momentum variable from the momentum
        canonical distribution $p_0 \sim p( p)$

    -   Set $x_0 =  x^\{(t-1)\}$

    -   run Leap Frog algorithm starting at $x_0$, $p_0$ for $L$ steps
        and step size $\delta$ to obtain proposed states $x^*$ and $p^*$

    -   calculate the Metropolis acceptance probability:

        $\alpha = \text\{min\}(1,\exp[-\beta(U(x^*)-U(x_0)+K(p^*)-K(p_0))])$

    -   draw a uniform random number, u.

    -   if $u \leq \alpha$ accept the proposed state position $x^*$ and
        set the next state in the Markov chain $x^\{(t)\}= x^*$

    -   else set $x^\{(t)\} = x^\{(t-1)\}$

Note that, in the case of a 2D magnetic Isiging system, $x$ corresponds
to a particular configuration of spins (for the entire system), while
$p$ is a set of rules on how these spins change with time (for instance,
magnons propagating through the material, dictating how the spins should
change from one time step to the next). In general $x$ correspond to the
system configuration, that is, the set of variables that uniquely
determines the potential energy $U$, while $p$ denotes an assortment of
rules that dictate how the variables in $x$ change in time.

::: marginfigure
![image](figures/part1b/monte_carlo/theta_t_hmc.png)\{width="\\linewidth"\}
![image](figures/part1b/monte_carlo/pdf_hmc.png)\{width="\\linewidth"\}
![image](figures/part1b/monte_carlo/autocorr_hmc.png)\{width="\\linewidth"\}
:::

### Improving convergence through Simulated annealing

The energy sampling for a particular value of T or $\beta$ could get
stuck in local minima. In order to avoid this, T is now ramped down from
a large value to the desired temperature, in appropriate steps. This
helps greatly in improving convergence.


# Approaching Nonlinear Systems with Newton's Method \{#chap:nonlinear_newton\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:linear_systems\]](#chap:linear_systems)\{reference-type="ref+label"
reference="chap:linear_systems"\},
[\[chap:matrix_calculus\]](#chap:matrix_calculus)\{reference-type="ref+label"
reference="chap:matrix_calculus"\}\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------

In this chapter we understand how non-linear systems are different from
linear systems. We then compute the Jacobian matrix for a multi-variable
system of equations and solve non-linear systems of equations with
Newton's Method.

## Introduction

Previously, we have seen how to solve a system of linear equations using
the Gaussian Elimination and LU Factorization techniques. These
techniques can be used, when the system of equations can be represented
as $$\begin\{aligned\}
Ax = b
\end\{aligned\}$$ where $A$ is the matrix of coefficients, $b$ is the
column vector of constants and $x$ is the column vector of unknowns.

Also, we focused on solving nonlinear equations involving only a single
variable using the root-finding techniques. These techniques include -
Bisection, Newton's method, Secant method and False Position method.
However, these problems only focused on solving nonlinear equations with
only one variable, rather than nonlinear equations with several
variables.

The goal of this chapter is to examine numerical methods that are used
to solve systems of nonlinear equations in several variables. The first
method we will look at is Newton's method. This is a straightforward
extension to the Newton-Raphson method of root-finding we have seen
before.

## Nonlinear System of Equations

A system of nonlinear equations is a system in which at least one of the
equations is nonlinear. We will be using the Taylor series approximation
to reduce the system of nonlinear equations to a linear one.

$$\begin\{aligned\}
F(X_i + \delta X)  \cong F(X_i) + J(X_i)\delta X
\end\{aligned\}$$

where $J$ is the analogous of the first derivative for multi-dimensional
system. The Jacobian matrix for a n-dimensional with n equations is
given as

$$\begin\{aligned\}
 J(X_i) = \begin\{bmatrix\}
 \frac\{\partial f_1\}\{\partial x_1\} & \frac\{\partial f_1\}\{\partial x_2\} & \frac\{\partial f_1\}\{\partial x_3\} & \dots  & \frac\{\partial f_1\}\{\partial x_n\} \\
 \frac\{\partial f_2\}\{\partial x_1\} & \frac\{\partial f_2\}\{\partial x_2\} & \frac\{\partial f_2\}\{\partial x_3\} & \dots  & \frac\{\partial f_2\}\{\partial x_n\} \\
 \vdots & \vdots & \vdots & \ddots & \vdots \\
 \frac\{\partial f_n\}\{\partial x_1\} & \frac\{\partial f_n\}\{\partial x_2\} & \frac\{\partial f_n\}\{\partial x_3\} & \dots  & \frac\{\partial f_n\}\{\partial x_n\} \\
 \end\{bmatrix\}
\end\{aligned\}$$

## Newton's Method

The Newton's method is a straight-forward extension to the
Newton-Raphson method of root finding. To recap, the Newton-Raphson
update for a root estimate is given as follows:

$$\begin\{aligned\}
 x_\{i+1\} = x_i - \dfrac\{f(x_i)\}\{f'(x_i)\}
 
\end\{aligned\}$$

The method starts with an initial guess of the root at $x_i$ and the
tangent to the function is drawn at the point $[x_i,f(x_i)]$. The point
where this tangent crosses the x-axis usually represents an improved
estimate of the root.

A similar update rule can be defined for the multi-dimensional system of
equations

$$\begin\{aligned\}
  X_\{i+1\} =X_\{i\} - J(X_\{i\})^\{-1\}F(X_\{i\})
\end\{aligned\}$$

where $i$ denotes the iteration number, $F$ denotes the non-linear
functions, $X_i$ denotes the solution estimate to the non-linear system
at $i^\{th\}$ iteration and $J(X_\{i\})$ denotes the Jacobian of $F$
evaluated at $X_\{i\}$ (this is analogous to the first derivative
evaluated at $x_i$ in the case of a single-variable function).

The above update rule can be re-written as

$$\begin\{aligned\}
X_\{i+1\} =X_\{i\} + \delta X_i 
\end\{aligned\}$$

with

$$\begin\{aligned\}
\delta X_i =  - J(X_\{i\})^\{-1\}F(X_\{i\})
\end\{aligned\}$$

This can be re-written as $$\begin\{aligned\}
J(X_\{i\})\delta X_i =  - F(X_\{i\})
\end\{aligned\}$$

Now, this becomes a linear-system of equations with $\delta X_i$ as
unknown variables, which we can solve using Gaussian-elimination or LU
factorization. This trick enables us to compute the updated solution
without computing the inverse. Thus, at every iteration, we are updating
the solution estimate by $\delta X_i$, which is obtained by solving a
linear system of equations.

### Robotic Arm Modeling

Consider the following planar robotic arm as shown in the figure. Given
the lengths of the links, how can we find the joint angles to reach a
specific target in the workspace by the end-effector of the robot using
the Newton's method? Let's start with an initial guess of 0.1 rad for
both the joint angles.

::: marginfigure
![image](figures/part1b/nonlinear_systems/RobotArm_0.png)\{width="2.6in"\}
:::

Let's assume $\theta_1$ and $\theta_2$ to be the joint angles of the
links which are required to be determined. Let $(x_t,y_t)$ be the
co-ordinate in the workspace to be reached by the end-effector.

Using the link-lengths, it can be observed that the end-effector
position can be represented in terms of joint angles as
$$\begin\{aligned\}
x_t = l_1 \cos(\theta_1) + l_2 \cos(\theta_1 + \theta_2)\\
y_t = l_1 \sin(\theta_1) + l_2 \sin(\theta_1 + \theta_2)
\end\{aligned\}$$ These can be re-written as a system of non-linear
equations as: $$\begin\{aligned\}
l_1 \cos(\theta_1) + l_2 \cos(\theta_1 + \theta_2) - x_t = 0\\
l_1 \sin(\theta_1) + l_2 \sin(\theta_1 + \theta_2) - y_t = 0
\end\{aligned\}$$

The Jacobian matrix of the above system of equations can be written as:
$$\begin\{aligned\}
J(\theta) = 
\begin\{bmatrix\}
\dfrac\{\partial x_t\}\{\partial \theta_1\} & \dfrac\{\partial x_t\}\{\partial \theta_2\} \\
\\
\dfrac\{\partial y_t\}\{\partial \theta_1\} & \dfrac\{\partial y_t\}\{\partial \theta_2\}\\
\end\{bmatrix\}
\end\{aligned\}$$

with

$$\begin\{aligned\}
\dfrac\{\partial x_t\}\{\partial \theta_1\} &= -l_1 \sin(\theta_1) - l_2 \sin(\theta_1 + \theta_2)\\
\dfrac\{\partial x_t\}\{\partial \theta_2\} &= -l_2 \sin(\theta_1 + \theta_2) \\
\dfrac\{\partial y_t\}\{\partial \theta_1\} &= l_1 \cos(\theta_1) + l_2 \cos(\theta_1 + \theta_2)\\
\dfrac\{\partial y_t\}\{\partial \theta_2\} &= l_2 \cos(\theta_1 + \theta_2)
\end\{aligned\}$$

Using the following equations, the guess of our joint angles is
continuously updated. $$\begin\{aligned\}
\theta_\{i+1\} =\theta_\{i\} + \delta\theta_i 
\end\{aligned\}$$ with $$\begin\{aligned\}
\delta\theta_i =  - J(\theta_\{i\})^\{-1\}F(\theta_\{i\})
\end\{aligned\}$$

``` \{.python language="python"\}
l1 = 1, l2 = 1 # Link Lengths
xt = 1, yt = 1 # Target Position

# Non-linear function
def f($\theta_1$: $\mathbb\{R\}$, $\theta_2$: $\mathbb\{R\}$) $\to$ $\mathbb\{R\}^2$:
  return [l1*cos($\theta_1$) + l2*cos($\theta_1$ + $\theta_2$) - xt; 
          l1*sin($\theta_1$) + l2*sin($\theta_1$ + $\theta_2$) - yt]

# Jacobian of the system of equations
def J($\theta_1$: $\mathbb\{R\}$,$\theta_2$: $\mathbb\{R\}$):
  return $\nabla$(f, [$\theta_1$, $\theta_2$])
```

We now define a Newton's method and apply it to this system.

``` \{.python language="python"\}
def newtons_method(f: $\mathbb\{R\}^N \to \mathbb\{R\}$, J: $\mathbb\{R\}[N, N]$, guess:$\mathbb\{R\}^N$, error: $\mathbb\{R\}$, tol: $\mathbb\{R\}$):
  while (error > tol):
    dGuess = -J(guess)$^\{-1\}$*f(guess) 
    guess = guess + dGuess
    # Wrap radians to [-$\pi$, $\pi$]
    guess = wrapToPi(guess)
    error = $\|$f(guess))$\|$
```

## Quasi-Newton Methods

Quasi-Newton methods are very similar to Newton's method. The general
form of these methods is given by:

$$\begin\{aligned\}
X_\{i+1\} = X_\{i\} - B_i^\{-1\}F(X_\{i\})
\end\{aligned\}$$

These methods avoid the necessity of computing the derivatives (or)
solving a full linear system per iteration (or) both.

The most-simplest Quasi-Newton method is the *Stationary Newton Method*,
where $B_i = J(X_0)$ for all iterations $i$. In other words, in this
method, the derivatives are computed at the initial point and we need
the LU decomposition for only $J(X_0)$.

A variation of this method is the *Stationary Newton Method with
restarts*, where $B_i = J(X_i)$ if $i$ is a multiple of a fixed integer
$n$. If $i$ is not a multiple of $n$, $B_i$ = $B_\{i-1\}$. The number of
iterations used by this method tends to increase with $n$, but the
average computation time per iteration decreases.

Broyden's method is also one such quasi-Newton method, which we will
look in detail.

### Broyden's Method

Newton's method for solving $f(x) = 0$ uses the Jacobian matrix at every
iteration. However, computing this Jacobian is a difficult and expensive
operation. The idea behind Broyden's method is to compute the whole
Jacobian only at the first iteration, and to do a rank-one update at the
other iterations.

Earlier, we have seen that in secant method, the derivative can be
approximated by a backward finite divided difference: $$\begin\{aligned\}
f'(x_i) \cong \dfrac\{f(x_\{i-1\}) - f(x_\{i\})\}\{x_\{i-1\} - x_\{i\}\}
\end\{aligned\}$$

which can be re-written as $$\begin\{aligned\}
f'(x_i) (x_\{i-1\} - x_\{i\}) \cong f(x_\{i-1\}) - f(x_\{i\})
\end\{aligned\}$$

Using the same intuition, we can approximate the Jacobian in the Secant
method as $$\begin\{aligned\}
J(X_\{i\})(X_\{i\} - X_\{i-1\}) \cong F(X_\{i\}) - F(X_\{i-1\})
\end\{aligned\}$$

However, this is an under-determined system with $n^2$ unknown variables
and $n$ equations.

Broyden's method uses the Newton's method update rule for the first
iteration and comes up with one feasible solution for updating the
Jacobian at every iteration.

To recap, Newton's method for $i^\{th\}$ iteration can be re-written as

$$\begin\{aligned\}
J(X_\{i-1\})(X_\{i\} - X_\{i-1\}) \cong - F(X_\{i-1\})
\end\{aligned\}$$

Subtracting the Secant method update and the Newton's method update, we
get

$$\begin\{aligned\}
(J(X_\{i\}) -     J(X_\{i-1\}))(X_\{i\} - X_\{i-1\}) \cong F(X_\{i\})
\end\{aligned\}$$

It can be observed that, one possible solution for the difference in
Jacobians between the two-iterations (given by Broyden) is

$$\begin\{aligned\}
J(X_\{i\}) - J(X_\{i-1\}) = \dfrac\{F(X_i)(X_\{i\} - X_\{i-1\})^T\}\{||X_\{i\} - X_\{i-1\}||_2\}
\end\{aligned\}$$

This is used for updating the Jacobian iteratively using the Broyden's
method, without computing it explicitly.

$$\begin\{aligned\}
J(X_\{i\})  = J(X_\{i-1\}) +    \dfrac\{F(X_\{i\})(X_\{i\} - X_\{i-1\})^T\}\{||X_\{i\} - X_\{i-1\}||_2\}
\end\{aligned\}$$

Now, Gauss-Newton (or) LU Decomposition can be used to solve the
following equation to obtain the iterative solution.

$$\begin\{aligned\}
J(X_\{i\})\delta X_i =  - F(X_\{i\})
\end\{aligned\}$$


# Level Set Methods \{#chap:phase_field_methods\}

------------------------------------------------------------------------

\
**Prerequisites:**
[\[chap:molecular_hamiltonian\]](#chap:molecular_hamiltonian)\{reference-type="ref+label"
reference="chap:molecular_hamiltonian"\},\
**Difficulty Level:** \*\*\

------------------------------------------------------------------------
